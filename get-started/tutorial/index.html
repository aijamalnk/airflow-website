<!DOCTYPE html>
<!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<html lang="en">
  <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Get Started</title>
  <meta name="description" content="Airflow is a platform to programmatically author, schedule and monitor workflows. Use airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The airflow scheduler executes your tasks on an array of workers while following the specified dependencies. Rich command line utilities make performing complex surgeries on DAGs a snap. The rich user interface makes it easy to visualize pipelines running in production, monitor progress, and troubleshoot issues when needed. When workflows are defined as code, they become more maintainable, versionable, testable, and collaborative.
">
  <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400" rel="stylesheet">
  <link rel="stylesheet" href="/airflow-website/css/site.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
  <script src="/airflow-website/js/bootstrap.min.js"></script>
  <script src="/airflow-website/js/language-switch.js"></script>
  <script src="/airflow-website/js/fix-menu.js"></script>
  <script src="/airflow-website/js/section-nav.js"></script>
  <script src="/airflow-website/js/page-nav.js"></script>
  <link rel="canonical" href="https://aijamalnk.github.io/airflow-website/get-started/tutorial/" data-proofer-ignore>
  <link rel="shortcut icon" type="image/x-icon" href="/airflow-website/images/favicon.ico">
  <link rel="alternate" type="application/rss+xml" title="Apache Airflow" href="https://aijamalnk.github.io/airflow-website/feed.xml">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-73650088-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

  <body class="body" data-spy="scroll" data-target=".page-nav" data-offset="0">
    <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<nav class="header navbar navbar-fixed-top">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <a href="/airflow-website/" class="navbar-brand" >
        <img alt="Brand" style="height: 25px" src="/airflow-website/images/logos/airflow_logo_navbar.png">
      </a>
    </div>

    <div class="navbar-mask closed"></div>

    <div id="navbar" class="navbar-container closed">
      <ul class="nav navbar-nav">
        <li>
          <a href="/airflow-website/project/">Project and Roadmap</a>
        </li>
        <li>
          <a href="/airflow-website/get-started/">Get Started</a>
        </li>
        <li>
          <!-- TODO(pabloem, aizhamal): Fix this link once site is merged -->
          <a href="/airflow-website/documentation/">Documentation</a>
        </li>
        <li>
          <a href="/airflow-website/contribute/">Contribute</a>
        </li>
        <li>
          <a href="/airflow-website/community/contact-us/">Community</a>
        </li>
        <li><a href="/airflow-website/blog">Blog</a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"><img src="https://www.apache.org/foundation/press/kit/feather_small.png" alt="Apache Logo" style="height:20px;"><span class="caret"></span></a>
          <ul class="dropdown-menu dropdown-menu-right">
            <li><a href="http://www.apache.org/">ASF Homepage</a></li>
            <li><a href="http://www.apache.org/licenses/">License</a></li>
            <li><a href="http://www.apache.org/security/">Security</a></li>
            <li><a href="http://www.apache.org/foundation/thanks.html">Thanks</a></li>
            <li><a href="http://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
            <li><a href="https://www.apache.org/foundation/policies/conduct">Code of Conduct</a></li>
          </ul>
        </li>
        <li>
          <!--
            data-proofer-ignore disables link checking from website test automation.
            GitHub links will not resolve until the markdown source is available on the master branch.
            New pages would fail validation during development / PR test automation.
          -->
          <a href="https://github.com/apache/airflow/edit/master/website/src/get-started/tutorial.md" data-proofer-ignore>
            <i class="far fa-edit fa-lg" alt="Edit on GitHub" title="Edit on GitHub"></i>
          </a>
        </li>
      </ul>
    </div>
</nav>

    <div class="clearfix container-main-content">
      <div class="section-nav closed" data-offset-top="90" data-offset-bottom="500">
        <span class="section-nav-back glyphicon glyphicon-menu-left"></span>
        <nav>
          <ul class="section-nav-list" data-section-nav>
            <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<li><span class="section-nav-list-main-title">Get started</span></li>
<li><a href="/airflow-website/get-started/">Quickstart</a></li>
<!--<li>
  <span class="section-nav-list-title">Quickstarts</span>

  <ul class="section-nav-list">
    <li><a href="/airflow-website/get-started/quickstart-java/">Quickstart - Java</a></li>
  </ul>
</li>-->
<li>
  <span class="section-nav-list-title">Example Walkthroughs</span>
  <ul class="section-nav-list">
     <li><a href="/airflow-website/get-started/tutorial">Tutorial</a></li>
   </ul>
</li>


          </ul>
        </nav>
      </div>

      <nav class="page-nav clearfix" data-offset-top="90" data-offset-bottom="500">
        <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->



<ul class="nav">
  <li><a href="#example-pipeline-definition">Example Pipeline definition</a>
    <ul>
      <li><a href="#its-a-dag-definition-file">It’s a DAG definition file</a></li>
      <li><a href="#importing-modules">Importing Modules</a></li>
      <li><a href="#default-arguments">Default Arguments</a></li>
      <li><a href="#instantiate-a-dag">Instantiate a DAG</a></li>
      <li><a href="#tasks">Tasks</a></li>
      <li><a href="#templating-with-jinja">Templating with Jinja</a></li>
      <li><a href="#setting-up-dependencies">Setting up Dependencies</a></li>
    </ul>
  </li>
  <li><a href="#recap">Recap</a>
    <ul>
      <li><a href="#testing">Testing</a></li>
    </ul>
  </li>
</ul>


      </nav>

      <div class="body__contained body__section-nav">
        <!--
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

<h1 id="tutorial">Tutorial</h1>

<p>This tutorial walks you through some of the fundamental Airflow concepts,
objects, and their usage while writing your first pipeline.</p>

<h2 id="example-pipeline-definition">Example Pipeline definition</h2>

<p>Here is an example of a basic pipeline definition. Do not worry if this looks
complicated, a line by line explanation follows below.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    """
    Code that goes along with the Airflow tutorial located at:
    https://github.com/apache/airflow/blob/master/airflow/example_dags/tutorial.py
    """
    from airflow import DAG
    from airflow.operators.bash_operator import BashOperator
    from datetime import datetime, timedelta


    default_args = {
        'owner': 'airflow',
        'depends_on_past': False,
        'start_date': datetime(2015, 6, 1),
        'email': ['airflow@example.com'],
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
        # 'queue': 'bash_queue',
        # 'pool': 'backfill',
        # 'priority_weight': 10,
        # 'end_date': datetime(2016, 1, 1),
    }

    dag = DAG('tutorial', default_args=default_args, schedule_interval=timedelta(days=1))

    # t1, t2 and t3 are examples of tasks created by instantiating operators
    t1 = BashOperator(
        task_id='print_date',
        bash_command='date',
        dag=dag)

    t2 = BashOperator(
        task_id='sleep',
        bash_command='sleep 5',
        retries=3,
        dag=dag)

    templated_command = """
        
    """

    t3 = BashOperator(
        task_id='templated',
        bash_command=templated_command,
        params={'my_param': 'Parameter I passed in'},
        dag=dag)

    t2.set_upstream(t1)
    t3.set_upstream(t1)
</code></pre>
</div>

<h3 id="its-a-dag-definition-file">It’s a DAG definition file</h3>

<p>One thing to wrap your head around (it may not be very intuitive for everyone
at first) is that this Airflow Python script is really
just a configuration file specifying the DAG’s structure as code.
The actual tasks defined here will run in a different context from
the context of this script. Different tasks run on different workers
at different points in time, which means that this script cannot be used
to cross communicate between tasks. Note that for this
purpose we have a more advanced feature called <code class="highlighter-rouge">XCom</code>.</p>

<p>People sometimes think of the DAG definition file as a place where they
can do some actual data processing - that is not the case at all!
The script’s purpose is to define a DAG object. It needs to evaluate
quickly (seconds, not minutes) since the scheduler will execute it
periodically to reflect the changes if any.</p>

<h3 id="importing-modules">Importing Modules</h3>

<p>An Airflow pipeline is just a Python script that happens to define an
Airflow DAG object. Let’s start by importing the libraries we will need.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code>
    <span class="c"># The DAG object; we'll need this to instantiate a DAG</span>
    <span class="kn">from</span> <span class="nn">airflow</span> <span class="kn">import</span> <span class="n">DAG</span>

    <span class="c"># Operators; we need this to operate!</span>
    <span class="kn">from</span> <span class="nn">airflow.operators.bash_operator</span> <span class="kn">import</span> <span class="n">BashOperator</span>

</code></pre>
</div>

<h3 id="default-arguments">Default Arguments</h3>

<p>We’re about to create a DAG and some tasks, and we have the choice to
explicitly pass a set of arguments to each task’s constructor
(which would become redundant), or (better!) we can define a dictionary
of default parameters that we can use when creating tasks.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    from datetime import datetime, timedelta

    default_args = {
        'owner': 'airflow',
        'depends_on_past': False,
        'start_date': datetime(2015, 6, 1),
        'email': ['airflow@example.com'],
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
        # 'queue': 'bash_queue',
        # 'pool': 'backfill',
        # 'priority_weight': 10,
        # 'end_date': datetime(2016, 1, 1),
    }
</code></pre>
</div>

<p>For more information about the BaseOperator’s parameters and what they do,
refer to the <code class="highlighter-rouge">airflow.models.BaseOperator</code> documentation.</p>

<p>Also, note that you could easily define different sets of arguments that
would serve different purposes. An example of that would be to have
different settings between a production and development environment.</p>

<h3 id="instantiate-a-dag">Instantiate a DAG</h3>

<p>We’ll need a DAG object to nest our tasks into. Here we pass a string
that defines the <code class="highlighter-rouge">dag_id</code>, which serves as a unique identifier for your DAG.
We also pass the default argument dictionary that we just defined and
define a <code class="highlighter-rouge">schedule_interval</code> of 1 day for the DAG.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    dag = DAG(
        'tutorial', default_args=default_args, schedule_interval=timedelta(days=1))
</code></pre>
</div>

<h3 id="tasks">Tasks</h3>

<p>Tasks are generated when instantiating operator objects. An object
instantiated from an operator is called a constructor. The first argument
<code class="highlighter-rouge">task_id</code> acts as a unique identifier for the task.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    t1 = BashOperator(
        task_id='print_date',
        bash_command='date',
        dag=dag)

    t2 = BashOperator(
        task_id='sleep',
        bash_command='sleep 5',
        retries=3,
        dag=dag)
</code></pre>
</div>

<p>Notice how we pass a mix of operator specific arguments (<code class="highlighter-rouge">bash_command</code>) and
an argument common to all operators (<code class="highlighter-rouge">retries</code>) inherited
from BaseOperator to the operator’s constructor. This is simpler than
passing every argument for every constructor call. Also, notice that in
the second task we override the <code class="highlighter-rouge">retries</code> parameter with <code class="highlighter-rouge">3</code>.</p>

<p>The precedence rules for a task are as follows:</p>

<ol>
  <li>Explicitly passed arguments</li>
  <li>Values that exist in the <code class="highlighter-rouge">default_args</code> dictionary</li>
  <li>The operator’s default value, if one exists</li>
</ol>

<p>A task must include or inherit the arguments <code class="highlighter-rouge">task_id</code> and <code class="highlighter-rouge">owner</code>,
otherwise Airflow will raise an exception.</p>

<h3 id="templating-with-jinja">Templating with Jinja</h3>

<p>Airflow leverages the power of
<a href="http://jinja.pocoo.org/docs/dev/">Jinja Templating</a> and provides
the pipeline author with a set of built-in parameters and macros. Airflow also 
provides hooks for the pipeline author to define their own parameters, macros and
templates.</p>

<p>This tutorial barely scratches the surface of what you can do with
templating in Airflow, but the goal of this section is to let you know
this feature exists, get you familiar with double curly brackets, and
point to the most common template variable: ```` (today’s “date
stamp”).</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    templated_command = """
    
        {% for i in range(5) %}
            echo "{{ ds }}"
            echo "{{ macros.ds_add(ds, 7) }}"
            echo "{{ params.my_param }}"
        {% endfor %}
    
    """

    t3 = BashOperator(
        task_id='templated',
        bash_command=templated_command,
        params={'my_param': 'Parameter I passed in'},
        dag=dag)
</code></pre>
</div>

<p>Notice that the <code class="highlighter-rouge">templated_command</code> contains code logic in <code class="highlighter-rouge"><span class="p">{</span><span class="err">%</span><span class="w"> </span><span class="err">%</span><span class="p">}</span></code> blocks,
references parameters like <code class="highlighter-rouge">, calls a function as in
</code>, and references a user-defined parameter
in ````.</p>

<p>The <code class="highlighter-rouge">params</code> hook in <code class="highlighter-rouge">BaseOperator</code> allows you to pass a dictionary of
parameters and/or objects to your templates. Please take the time
to understand how the parameter <code class="highlighter-rouge">my_param</code> makes it through to the template.</p>

<p>Files can also be passed to the <code class="highlighter-rouge">bash_command</code> argument, like
<code class="highlighter-rouge">bash_command='templated_command.sh'</code>, where the file location is relative to
the directory containing the pipeline file (<code class="highlighter-rouge">tutorial.py</code> in this case). This
may be desirable for many reasons, like separating your script’s logic and
pipeline code, allowing for proper code highlighting in files composed in
different languages, and general flexibility in structuring pipelines. It is
also possible to define your <code class="highlighter-rouge">template_searchpath</code> as pointing to any folder
locations in the DAG constructor call.</p>

<p>Using that same DAG constructor call, it is possible to define
<code class="highlighter-rouge">user_defined_macros</code> which allow you to specify your own variables.
For example, passing <code class="highlighter-rouge">dict(foo='bar')</code> to this argument allows you
to use ```` in your templates. Moreover, specifying
<code class="highlighter-rouge">user_defined_filters</code> allow you to register you own filters. For example,
passing <code class="highlighter-rouge">dict(hello=lambda name: 'Hello %s' % name)</code> to this argument allows
you to use <code class="highlighter-rouge">world</code> in your templates. For more information
regarding custom filters have a look at the
<code class="highlighter-rouge">Jinja Documentation &lt;http://jinja.pocoo.org/docs/dev/api/#writing-filters&gt;</code>_</p>

<p>For more information on the variables and macros that can be referenced
in templates, make sure to read through the :ref:<code class="highlighter-rouge">macros</code> section</p>

<h3 id="setting-up-dependencies">Setting up Dependencies</h3>

<p>We have tasks <code class="highlighter-rouge">t1</code>, <code class="highlighter-rouge">t2</code> and <code class="highlighter-rouge">t3</code> that do not depend on each other. Here’s a few ways
you can define dependencies between them:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    t1.set_downstream(t2)

    # This means that t2 will depend on t1
    # running successfully to run.
    # It is equivalent to:
    t2.set_upstream(t1)

    # The bit shift operator can also be
    # used to chain operations:
    t1 &gt;&gt; t2

    # And the upstream dependency with the
    # bit shift operator:
    t2 &lt;&lt; t1

    # Chaining multiple dependencies becomes
    # concise with the bit shift operator:
    t1 &gt;&gt; t2 &gt;&gt; t3

    # A list of tasks can also be set as
    # dependencies. These operations
    # all have the same effect:
    t1.set_downstream([t2, t3])
    t1 &gt;&gt; [t2, t3]
    [t2, t3] &lt;&lt; t1
</code></pre>
</div>

<p>Note that when executing your script, Airflow will raise exceptions when
it finds cycles in your DAG or when a dependency is referenced more
than once.</p>

<h2 id="recap">Recap</h2>
<p>Alright, so we have a pretty basic DAG. At this point your code should look
something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    """
    Code that goes along with the Airflow tutorial located at:
    https://github.com/apache/airflow/blob/master/airflow/example_dags/tutorial.py
    """
    from airflow import DAG
    from airflow.operators.bash_operator import BashOperator
    from datetime import datetime, timedelta


    default_args = {
        'owner': 'airflow',
        'depends_on_past': False,
        'start_date': datetime(2015, 6, 1),
        'email': ['airflow@example.com'],
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
        # 'queue': 'bash_queue',
        # 'pool': 'backfill',
        # 'priority_weight': 10,
        # 'end_date': datetime(2016, 1, 1),
    }

    dag = DAG(
        'tutorial', default_args=default_args, schedule_interval=timedelta(days=1))

    # t1, t2 and t3 are examples of tasks created by instantiating operators
    t1 = BashOperator(
        task_id='print_date',
        bash_command='date',
        dag=dag)

    t2 = BashOperator(
        task_id='sleep',
        bash_command='sleep 5',
        retries=3,
        dag=dag)

    templated_command = """
        
    """

    t3 = BashOperator(
        task_id='templated',
        bash_command=templated_command,
        params={'my_param': 'Parameter I passed in'},
        dag=dag)

    t2.set_upstream(t1)
    t3.set_upstream(t1)
</code></pre>
</div>

<h3 id="testing">Testing</h3>

<h4 id="running-the-script">Running the Script</h4>

<p>Time to run some tests. First, let’s make sure the pipeline
is parsed successfully.</p>

<p>Let’s assume we’re saving the code from the previous step in
<code class="highlighter-rouge">tutorial.py</code> in the DAGs folder referenced in your <code class="highlighter-rouge">airflow.cfg</code>.
The default location for your DAGs is <code class="highlighter-rouge">~/airflow/dags</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    python ~/airflow/dags/tutorial.py
</code></pre>
</div>

<p>If the script does not raise an exception it means that you haven’t done
anything horribly wrong, and that your Airflow environment is somewhat
sound.</p>

<h4 id="command-line-metadata-validation">Command Line Metadata Validation</h4>

<p>Let’s run a few commands to validate this script further.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    # print the list of active DAGs
    airflow list_dags

    # prints the list of tasks in the "tutorial" DAG
    airflow list_tasks tutorial

    # prints the hierarchy of tasks in the "tutorial" DAG
    airflow list_tasks tutorial --tree
</code></pre>
</div>

<h4 id="testing-1">Testing</h4>

<p>Let’s test by running the actual task instances on a specific date. The
date specified in this context is an <code class="highlighter-rouge">execution_date</code>, which simulates the
scheduler running your task or dag at a specific date + time:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    # command layout: command subcommand dag_id task_id date

    # testing print_date
    airflow test tutorial print_date 2015-06-01

    # testing sleep
    airflow test tutorial sleep 2015-06-01
</code></pre>
</div>

<p>Now remember what we did with templating earlier? See how this template
gets rendered and executed by running this command:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    # testing templated
    airflow test tutorial templated 2015-06-01
</code></pre>
</div>

<p>This should result in displaying a verbose log of events and ultimately
running your bash command and printing the result.</p>

<p>Note that the <code class="highlighter-rouge">airflow test</code> command runs task instances locally, outputs
their log to stdout (on screen), doesn’t bother with dependencies, and
doesn’t communicate state (running, success, failed, …) to the database.
It simply allows testing a single task instance.</p>

<h4 id="backfill">Backfill</h4>

<p>Everything looks like it’s running fine so let’s run a backfill.
<code class="highlighter-rouge">backfill</code> will respect your dependencies, emit logs into files and talk to
the database to record status. If you do have a webserver up, you’ll be able
to track the progress. <code class="highlighter-rouge">airflow webserver</code> will start a web server if you
are interested in tracking the progress visually as your backfill progresses.</p>

<p>Note that if you use <code class="highlighter-rouge">depends_on_past=True</code>, individual task instances
will depend on the success of the preceding task instance, except for the
start_date specified itself, for which this dependency is disregarded.</p>

<p>The date range in this context is a <code class="highlighter-rouge">start_date</code> and optionally an <code class="highlighter-rouge">end_date</code>,
which are used to populate the run schedule with task instances from this dag.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>
    # optional, start a web server in debug mode in the background
    # airflow webserver --debug &amp;

    # start your backfill on a date range
    airflow backfill tutorial -s 2015-06-01 -e 2015-06-07
</code></pre>
</div>

<h4 id="whats-next">What’s Next?</h4>

<p>That’s it, you’ve written, tested and backfilled your very first Airflow
pipeline. Merging your code into a code repository that has a master scheduler
running against it should get it to get triggered and run every day.</p>

<p>Here’s a few things you might want to do next:</p>

<ul>
  <li>Take an in-depth tour of the UI - click all the things!</li>
  <li>
    <p>Keep reading the docs! Especially the sections on:</p>

    <ul>
      <li>Command line interface</li>
      <li>Operators</li>
      <li>Macros</li>
    </ul>
  </li>
  <li>Write your first pipeline!</li>
</ul>

      </div>
    </div>
    <!--
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
   http://www.apache.org/licenses/LICENSE-2.0
 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License. See accompanying LICENSE file.
-->

<footer class="footer">
  <div class="footer__contained">
    <div class="footer__cols">
      <div class="footer__cols__col">
         <div class="footer__cols__col__logo">
          <img src="/airflow-website/images/logos/airflow_logo_small.png" class="footer__logo" alt="Airflow logo">
        </div>
        <div class="footer__cols__col__logo">
          <img src="/airflow-website/images/logos/apache_logo_simple.svg" class="footer__logo" alt="Apache logo">
        </div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Start</div>
        <div class="footer__cols__col__link"><a href="/airflow-website/project/">Overview</a></div>
        <div class="footer__cols__col__link"><a href="/airflow-website/get-started/">Quickstart</a></div>
        <div class="footer__cols__col__link"><a href="https://airflow.apache.org/installation.html">Downloads</a></div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Docs</div>
        <div class="footer__cols__col__link"><a href="https://airflow.apache.org/">ReadTheDocs</a></div>
        <div class="footer__cols__col__link"><a href="https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Home">Confluence Wiki</a></div>
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Community</div>
        <div class="footer__cols__col__link"><a href="/airflow-website/contribute/">Contribute</a></div>
       <!--<div class="footer__cols__col__link"><a href="/airflow-website/contribute/presentation-materials/">Media</a></div>-->
      </div>
      <div class="footer__cols__col footer__cols__col--md">
        <div class="footer__cols__col__title">Resources</div>
        <div class="footer__cols__col__link"><a href="/airflow-website/blog/">Blog</a></div>
        <div class="footer__cols__col__link"><a href="/airflow-website/community/contact-us/">Support</a></div>
        <div class="footer__cols__col__link"><a href="https://github.com/apache/airflow">GitHub</a></div>
      </div>
    </div>
  </div>
  <div class="footer__bottom">
    &copy;
    <a href="http://www.apache.org">The Apache Software Foundation</a>
    | <a href="/airflow-website/privacy_policy">Privacy Policy</a>
    | <a href="/airflow-website/feed.xml">RSS Feed</a>
    <br><br>
    Apache Airflow, Apache, Airflow, the Airflow logo, and the Apache feather logo are
    either registered trademarks or trademarks of The Apache Software
    Foundation. All other products or name brands are trademarks of their
    respective holders, including The Apache Software Foundation.
  </div>
</footer>

  </body>
</html>
